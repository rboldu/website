<!doctype html>
<html lang="en">
  <head>

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Ph.D Candidate, The Augmented Human Lab">
    <meta name="author" content="Roger Boldu">
    <meta name="theme-color" content="#222222">

    <link rel="apple-touch-icon" sizes="180x180" href="images/nicons/apple-touch-icon_2.png">
    <link rel="icon" type="image/png" sizes="32x32" href="images/nicons/fapple-touch-icon_2.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/nicons/apple-touch-icon_2.png">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="assets/style.css">
      
    <title>Roger Boldu</title>
  </head>
  <body>
    <!-- <h1>Hello, world!</h1> -->
    <div class="container pt-5 allstuffp">
        <div class="row pt-5 allstuff">
            <div class="col-md-4 pt-5">
                <div class="fixed-posi">
                <p class="name text-center">Roger Boldú</p>
                <img src="images/profile-pixel.png" class="profilepic pt-3 pb-2">
                <div class="text-center"><a class="menulink" target="_blank" href="assets/Roger_CV_web.pdf">Curriculum Vitae</a></div>
                <div class="text-center"><a class="menulink" target="_blank" href="https://scholar.google.com.sg/citations?hl=en&user=-2nSJYQAAAAJ">Google Scholar</a></div>
                <div class="text-center"><a class="menulink" target="_blank" href="mailto:roger.boldu@gmail.com">roger.boldu@gmail.com</a></div>
                <!-- <div class=""><a class="menulink" target="_blank" href="https://github.com/rboldu">Github</a></div> -->
                <div class="text-center"><a class="menulink" target="_blank" href="https://www.linkedin.com/in/roger-boldu/">Linkedin</a></div>
                

                <!-- <div class="pt-5">usercontext</div> -->
                <!-- <div class="">travel history</div> -->
                <!-- <div class="">this template</div> -->
                </div>
            </div>
            <div class="col-md-8 pt-5 about">
                I am currently a Ph.D. student at the Augmented Human Lab
                <a class="in-text" href="https://www.ahlab.org"
                     target="_blank">(AHLAB)</a>
                , The University of Auckland, advised by 
                <a class="in-text" href="https://suranga.info/"
                     target="_blank">Prof. Suranga Nanayakkara</a>.
                My research focuses on designing novel input-output wearable devices that enable users to interact with the environment naturally. 
                I like to bring my research beyond the laboratory environment and positively impact people's lives by combining my skills in Human-Computer Interaction(HCI), Robotics, Machine Learning, and Electronics. 
                 <!-- This has driven me to join 
                <a class="in-text" href="https://enterprise.nus.edu.sg/education-programmes/lean-launchpad-singapore/"
                     target="_blank">research commercialization</a> and <a class="in-text" href="https://Brinc.io"
                     target="_blank">hardware manufacturing</a> acceleration programs.
 -->

                <br> <br>


               

                 I graduated with a B.Sc.(Honours) in Electronics and Telecommunications from <a class="in-text"
                     href="https://www.salleurl.edu/en/" target="_blank">Ramon University - La Salle Bonanova</a>, Barcelona, Spain in 2015, and I have conducted HCI research at Auckland Bioengineering Institute <a class="in-text" href="https://www.auckland.ac.nz/en/abi.html" target="_blank"> (ABI)</a>, Massachusetts Institute of Technology <a class="in-text" href="https://www.media.mit.edu/groups/fluid-interfaces/overview/" target="_blank"> MIT Media Lab</a>, and Singapore University of Technology and Design 
                <a class="in-text" href="https://www.sutd.edu.sg/" target="_blank"> (SUTD)</a>.
                 <br><br>
                      I am now looking for full-time positions to start from May 2021. For more details, check my <a class="in-text" href="assets/Roger_CV_web.pdf" target="_blank">CV</a> or contact me via <a class="in-text" href="mailto:roger.boldu@gmail.com">email</a>.



                 <p class="header pt-5">Publications</p>

                <!-------------------- AI-SE ------------------------>
                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/AISee_2.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Boldu, R., Matthies, D.J.C., Zhang, H., & Nanayakkara, S. (2020). AiSee: An Assistive Wearable Device to Support Visually Impaired Grocery Shoppers</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> In Proceedings of the ACM Interact. Mob. Wearable Ubiquitous Technologies <a class="confshort" href="https://doi.org/10.1145/3432196">(IMWUT)</a> 4, 4, Article 119. </span><br>
                     <a class="tag" href="papers/Boldu_AiSee_IMWUT2020.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/505160299" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>


                                 <!-------------------- MagHair ------------------------>
                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/MagHair_2.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     

                     <span class="papertitle">Boldu, R., Wijewardena, M., Zhang, H. and Nanayakkara, S. (2020). MAGHair: A Wearable System to Create Unique Tactile Feedback by Stimulating Only the Body Hair.</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> In 22nd International Conference on Human-Computer Interaction with Mobile Devices and Services <a class="confshort" href="https://dl.acm.org/doi/fullHtml/10.1145/3379503.3403545">(MobileHCI)</a> (pp. 1-10). </span><br>
                     <a class="tag" href="papers/MagHair.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/505178886" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>





                                 <!-------------------- M-Hair ------------------------>
                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/M-Hair.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     

                     <span class="papertitle">Boldu, R., Jain, S., Forero Cortes, J.P., Zhang, H. and Nanayakkara, S. (2019). M-Hair: Creating Novel Tactile Feedback by Augmenting the Body Hair to Respond to Magnetic Field.</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> In Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology (UIST)</a> (pp. 323-328). </span><br>
                     <a class="tag" href="papers/M-Hair.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/378694032" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>




                <!-------------------- ARS ELECTRONICA ------------------------>

                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/LightTank.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Rieger, U., Liu, Y., Boldu, R., Zhang, H., Alwani, H. and Nanayakkara, S. LightTank is a mixed reality interactive installation that augments a space frame structure with holographic line drawings (2018).</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> In ARS Eletronica 2018 & SIGGRAPH Asia 2020 Art Gallery </span><br>

                     <a class="tag" href="papers/LightTank.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/505154657" target="_blank">video</a><span class="tagsep">|</span>
                     <a class="tag" href="https://www.arc-sec.com/lighttank" target="_blank">link</a><span class="tagsep">|</span>
                     
                 </p>
                 </div>
                 </div>
                 </div>



                <!-------------------- THUMB in MOTION ------------------------>

                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/ThumbInMotion.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Boldu, R., Dancu, A., Matthies, D.J., Cascón, P.G., Ransir, S. and Nanayakkara, S. (2018). Thumb-In-Motion: Evaluating Thumb-to-Ring Microgestures for Athletic Activity.</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> In Proceedings of the Symposium on Spatial User Interaction <a class="confshort" href="https://doi.org/10.1145/3267782.3267796">(SUI)</a>, (pp. 150-157). </span><br>

                     <a class="tag" href="papers/Boldu_Thumb-in-Motion_SUI2018.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/378693967" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>



                <!-------------------- FingerReader-2.0E ------------------------>

                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/FingerReader2.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Boldu, R., Dancu, A., Matthies, D.J.C., Buddhika, T., Siriwardhana, S., and Nanayakkara, S. (2018). FingerReader2.0: Designing and Evaluating a Wearable Finger-Worn Camera to Assist People with Visual Impairments while Shopping</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> In Proceedings of ACM Interact. Mob. Wearable Ubiquitous Technologies <a class="confshort" href="https://doi.org/10.1145/3264904">(IMWUT)</a>, Vol. 2, No. 3, Article 94 ACM. </span><br>

                     <a class="tag" href="papers/Boldu_FingerReader2.0_IMWUT2018.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/378693839" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>





                                 <!-------------------- FingerReader ------------------------>

                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/FingerReaderBooks.jpg" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Shilkrot, R., Huber, J., Boldu, R., Maes, P., and Nanayakkara, S. (2018). FingerReader: A Finger-Worn Assistive Augmentation</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> <a class="confshort" href="https://doi.org/10.1007/978-981-10-6404-3_9"> In Assistive Augmentation</a>, (pp. 151-175). Springer, Singapore. </span><br>

                     <a class="tag" href="https://doi.org/10.1007/978-981-10-6404-3_9" target="_blank">link</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/196407073" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>



                                 <!-------------------- InSight ------------------------>

                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/InSight.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Boldu, R., Zhang, H., Cortés, J.P.F., Muthukumarana, S. and Nanayakkara, S. (2017). Insight: a systematic approach to create dynamic human-controller-interactions.</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> In Proceedings of the 8th Augmented Human International Conference (AH) (pp. 1-5).</span><br>

                     <a class="tag" href="papers/inSight_ah2017.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/124890695" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>




                                 <!-------------------- Riboon ------------------------>

                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/RiBbon.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Nanayakkara, S. C., Schroepfer, T., Boldu, R., Muthukumarana, S. Withana, A., Lian, A. Dec 2015-Jan 2016. The RIBbon is an interactive lighting and architectural installation that responds to pedestrian activity along the bridge inducing varying intensities and colours.</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> Read Bridge at Clarke Quay, Singapore. Funded by Singapore River One.</span><br>

                     <a class="tag" href="https://vimeo.com/505468343" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>


                                 <!-------------------- TagMe ------------------------>

                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/TagMe.jpg" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Amores, J., Benavides, X., Boldu, R. and Maes, P. (2015). Exploring the design of a wearable device to turn everyday objects into playful experiences.</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> In Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA) (pp. 2145-2150).</span><br>

                     <a class="tag" href="https://doi.org/10.1145/2702613.2732885" target="_blank">link</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/118487753" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>



                                <!-------------------- Veo&Pleo ------------------------>

                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/PleoVleo.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Fernández-Baena, A., Boldú, R., Albo-Canals, J. and Miralles, D. (2015). Interaction between Vleo and Pleo, a virtual social character and a social robot.</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> In 2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN) (pp. 694-699). IEEE.</span><br>

                     <a class="tag" href="papers/VeoPleo.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/119307288" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>



                                <!-------------------- Robocup ------------------------>

                 <div class="py-2">
                    <div class="row">
                    <div class="col-4">
                    <img src="images/robocup.png" class="img-fluid pt-3 pb-2">
                    </div>
                    <div class="col-8">
                    <p class="paper my-2 pl-2">
                     
                     <span class="papertitle">Zhu, C.L., Boldú, R., de Saint Germain, C., Ubach, S.X., Albó, J. and Pfeiffer, S., The Reem@ LaSalle (2014) Using the robot REEM-H2. Developing ROS-based software modules to execute daily human tasks such as grasping, object and speech recognition<.</span><br>
<!--                      <span class="thisauthor">Boldu, R.</span>, Matthies, D.J.C., Zhang, H., & Nanayakkara, S.
 -->                     <!-- <span class="noter"> (* = Equal Contribution)</span><br> -->
                     <span class="conf"> International RoboCup 2014 - @Home Category, João Pessoa, Brazil. </span><br>

                     <a class="tag" href="papers/robocup.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://vimeo.com/119290398" target="_blank">video</a><span class="tagsep">|</span>
                 </p>
                 </div>
                 </div>
                 </div>









                <div class="row text-center py-4">
<!--                     <div class="mx-auto mt-2">
                        <img class="img-fluid instilogo p-1" src="images/bitspilani.png">
                        <div class="institution">BITS Pilani</div>
                        <div class="years">2015 - 2018</div>
                    </div>
                    <div class="mx-auto mt-2">
                        <img class="img-fluid instilogo p-3" src="images/mozilla1.png">
                        <div class="institution">Mozilla</div>
                        <div class="years">S2017</div>
                    </div>
                    <div class="mx-auto mt-2">
                        <img class="img-fluid instilogo p-2" src="images/julia1.png">
                        <div class="institution">Julia Computing</div>
                        <div class="years">S2018</div>
                    </div>
                    <div class="mx-auto mt-2">
                        <img class="img-fluid instilogo p-3" src="images/ucl1.png">
                        <div class="institution">University College London</div>
                        <div class="years">S2018</div>
                    </div>
                    <div class="mx-auto mt-2">
                        <img class="img-fluid instilogo p-1" src="images/CMU1.png">
                        <div class="institution">Carnegie Mellon</div>
                        <div class="years">F2018</div>
                    </div>
                    <div class="mx-auto mt-2">
                        <img class="img-fluid instilogo p-2" src="images/microsoft_research_logo.jpg">
                        <div class="institution">Microsoft Research</div>
                        <div class="years">2019 - Present</div>
                    </div>
                </div> -->

            </div>
            
        </div>
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
    <script src="assets/style.js"></script>
</body>
  <style>
  </style>
</html>